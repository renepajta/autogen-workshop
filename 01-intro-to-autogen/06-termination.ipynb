{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Termination \n",
    "\n",
    "In the previous section, we explored how to define agents, and organize them into teams that can solve tasks. However, a run can go on forever, and in many cases, we need to know _when_ to stop them. This is the role of the termination condition.\n",
    "\n",
    "AgentChat supports several termination condition by providing a base `~autogen_agentchat.base.TerminationCondition` class and several implementations that inherit from it.\n",
    "\n",
    "A termination condition is a callable that takes a sequence of `~autogen_agentchat.messages.BaseAgentEvent` or `~autogen_agentchat.messages.BaseChatMessage` objects **since the last time the condition was called**, and returns a `~autogen_agentchat.messages.StopMessage` if the conversation should be terminated, or `None` otherwise.\n",
    "Once a termination condition has been reached, it must be reset by calling `~autogen_agentchat.base.TerminationCondition.reset` before it can be used again.\n",
    "\n",
    "Some important things to note about termination conditions: \n",
    "- They are stateful but reset automatically after each run (`~autogen_agentchat.base.TaskRunner.run` or `~autogen_agentchat.base.TaskRunner.run_stream`) is finished.\n",
    "- They can be combined using the AND and OR operators.\n",
    "\n",
    "```{note}\n",
    "For group chat teams (i.e., `~autogen_agentchat.teams.RoundRobinGroupChat`,\n",
    "`~autogen_agentchat.teams.SelectorGroupChat`, and `~autogen_agentchat.teams.Swarm`),\n",
    "the termination condition is called after each agent responds.\n",
    "While a response may contain multiple inner messages, the team calls its termination condition just once for all the messages from a single response.\n",
    "So the condition is called with the \"delta sequence\" of messages since the last time it was called.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built-In Termination Conditions: \n",
    "1. `~autogen_agentchat.conditions.MaxMessageTermination`: Stops after a specified number of messages have been produced, including both agent and task messages.\n",
    "2. `~autogen_agentchat.conditions.TextMentionTermination`: Stops when specific text or string is mentioned in a message (e.g., \"TERMINATE\").\n",
    "3. `~autogen_agentchat.conditions.TokenUsageTermination`: Stops when a certain number of prompt or completion tokens are used. This requires the agents to report token usage in their messages.\n",
    "4. `~autogen_agentchat.conditions.TimeoutTermination`: Stops after a specified duration in seconds.\n",
    "5. `~autogen_agentchat.conditions.HandoffTermination`: Stops when a handoff to a specific target is requested. Handoff messages can be used to build patterns such as `~autogen_agentchat.teams.Swarm`. This is useful when you want to pause the run and allow application or user to provide input when an agent hands off to them.\n",
    "6. `~autogen_agentchat.conditions.SourceMatchTermination`: Stops after a specific agent responds.\n",
    "7. `~autogen_agentchat.conditions.ExternalTermination`: Enables programmatic control of termination from outside the run. This is useful for UI integration (e.g., \"Stop\" buttons in chat interfaces).\n",
    "8. `~autogen_agentchat.conditions.StopMessageTermination`: Stops when a `~autogen_agentchat.messages.StopMessage` is produced by an agent.\n",
    "9. `~autogen_agentchat.conditions.TextMessageTermination`: Stops when a `~autogen_agentchat.messages.TextMessage` is produced by an agent.\n",
    "10. `~autogen_agentchat.conditions.FunctionCallTermination`: Stops when a `~autogen_agentchat.messages.ToolCallExecutionEvent` containing a `~autogen_core.models.FunctionExecutionResult` with a matching name is produced by an agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "To demonstrate the characteristics of termination conditions, we'll create a team consisting of two agents: a primary agent responsible for text generation and a critic agent that reviews and provides feedback on the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)  # Load environment variables from .env file\n",
    "\n",
    "# Load environment variables\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "model_name = os.getenv(\"AZURE_OPENAI_MODEL_NAME\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "base_url = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "az_model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=deployment_name,\n",
    "    model=model_name,\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=base_url,\n",
    "    # azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    api_key=api_key, # For key-based authentication.\n",
    ")\n",
    "# Create the primary agent.\n",
    "primary_agent = AssistantAgent(\n",
    "    \"primary\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"You are a helpful AI assistant.\",\n",
    ")\n",
    "\n",
    "# Create the critic agent.\n",
    "critic_agent = AssistantAgent(\n",
    "    \"critic\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"Provide constructive feedback for every message. Respond with 'APPROVE' to when your feedbacks are addressed.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore how termination conditions automatically reset after each `run` or `run_stream` call, allowing the team to resume its conversation from where it left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_msg_termination = MaxMessageTermination(max_messages=3)\n",
    "round_robin_team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=max_msg_termination)\n",
    "\n",
    "# Use asyncio.run(...) if you are running this script as a standalone script.\n",
    "await Console(round_robin_team.run_stream(task=\"Write a unique, Haiku about the weather in Paris\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conversation stopped after reaching the maximum message limit. Since the primary agent didn't get to respond to the feedback, let's continue the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use asyncio.run(...) if you are running this script as a standalone script.\n",
    "await Console(round_robin_team.run_stream())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The team continued from where it left off, allowing the primary agent to respond to the feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Termination Conditions\n",
    "\n",
    "Let's show how termination conditions can be combined using the AND (`&`) and OR (`|`) operators to create more complex termination logic. For example, we'll create a team that stops either after 10 messages are generated or when the critic agent approves a message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_msg_termination = MaxMessageTermination(max_messages=10)\n",
    "text_termination = TextMentionTermination(\"APPROVE\")\n",
    "combined_termination = max_msg_termination | text_termination\n",
    "\n",
    "round_robin_team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=combined_termination)\n",
    "\n",
    "# Use asyncio.run(...) if you are running this script as a standalone script.\n",
    "await Console(round_robin_team.run_stream(task=\"Write a unique, Haiku about the weather in Paris\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conversation stopped after the critic agent approved the message, although it could have also stopped if 10 messages were generated.\n",
    "\n",
    "Alternatively, if we want to stop the run only when both conditions are met, we can use the AND (`&`) operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_termination = max_msg_termination & text_termination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Termination Condition\n",
    "\n",
    "The built-in termination conditions are sufficient for most use cases.\n",
    "However, there may be cases where you need to implement a custom termination condition that doesn't fit into the existing ones.\n",
    "You can do this by subclassing the `~autogen_agentchat.base.TerminationCondition` class.\n",
    "\n",
    "In this example, we create a custom termination condition that stops the conversation when\n",
    "a specific function call is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from autogen_agentchat.base import TerminatedException, TerminationCondition\n",
    "from autogen_agentchat.messages import BaseAgentEvent, BaseChatMessage, StopMessage, ToolCallExecutionEvent\n",
    "from autogen_core import Component\n",
    "from pydantic import BaseModel\n",
    "from typing_extensions import Self\n",
    "\n",
    "\n",
    "class FunctionCallTerminationConfig(BaseModel):\n",
    "    \"\"\"Configuration for the termination condition to allow for serialization\n",
    "    and deserialization of the component.\n",
    "    \"\"\"\n",
    "\n",
    "    function_name: str\n",
    "\n",
    "\n",
    "class FunctionCallTermination(TerminationCondition, Component[FunctionCallTerminationConfig]):\n",
    "    \"\"\"Terminate the conversation if a FunctionExecutionResult with a specific name is received.\"\"\"\n",
    "\n",
    "    component_config_schema = FunctionCallTerminationConfig\n",
    "    component_provider_override = \"autogen_agentchat.conditions.FunctionCallTermination\"\n",
    "    \"\"\"The schema for the component configuration.\"\"\"\n",
    "\n",
    "    def __init__(self, function_name: str) -> None:\n",
    "        self._terminated = False\n",
    "        self._function_name = function_name\n",
    "\n",
    "    @property\n",
    "    def terminated(self) -> bool:\n",
    "        return self._terminated\n",
    "\n",
    "    async def __call__(self, messages: Sequence[BaseAgentEvent | BaseChatMessage]) -> StopMessage | None:\n",
    "        if self._terminated:\n",
    "            raise TerminatedException(\"Termination condition has already been reached\")\n",
    "        for message in messages:\n",
    "            if isinstance(message, ToolCallExecutionEvent):\n",
    "                for execution in message.content:\n",
    "                    if execution.name == self._function_name:\n",
    "                        self._terminated = True\n",
    "                        return StopMessage(\n",
    "                            content=f\"Function '{self._function_name}' was executed.\",\n",
    "                            source=\"FunctionCallTermination\",\n",
    "                        )\n",
    "        return None\n",
    "\n",
    "    async def reset(self) -> None:\n",
    "        self._terminated = False\n",
    "\n",
    "    def _to_config(self) -> FunctionCallTerminationConfig:\n",
    "        return FunctionCallTerminationConfig(\n",
    "            function_name=self._function_name,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def _from_config(cls, config: FunctionCallTerminationConfig) -> Self:\n",
    "        return cls(\n",
    "            function_name=config.function_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this new termination condition to stop the conversation when the critic agent approves a message\n",
    "using the `approve` function call.\n",
    "\n",
    "First we create a simple function that will be called when the critic agent approves a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approve() -> None:\n",
    "    \"\"\"Approve the message when all feedbacks have been addressed.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create the agents. The critic agent is equipped with the `approve` tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "az_model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=deployment_name,\n",
    "    model=model_name,\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=base_url,\n",
    "    # azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    api_key=api_key, # For key-based authentication.\n",
    ")\n",
    "\n",
    "# Create the primary agent.\n",
    "primary_agent = AssistantAgent(\n",
    "    \"primary\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"You are a helpful AI assistant.\",\n",
    ")\n",
    "\n",
    "# Create the critic agent with the approve function as a tool.\n",
    "critic_agent = AssistantAgent(\n",
    "    \"critic\",\n",
    "    model_client=az_model_client,\n",
    "    tools=[approve],  # Register the approve function as a tool.\n",
    "    system_message=\"Provide constructive feedback. Use the approve tool to approve when all feedbacks are addressed.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create the termination condition and the team.\n",
    "We run the team with the poem-writing task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_call_termination = FunctionCallTermination(function_name=\"approve\")\n",
    "round_robin_team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=function_call_termination)\n",
    "\n",
    "# Use asyncio.run(...) if you are running this script as a standalone script.\n",
    "await Console(round_robin_team.run_stream(task=\"Write a unique, Haiku about the weather in Paris\"))\n",
    "await az_model_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the conversation stopped when the critic agent approved the message using the `approve` function call."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
