{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e358d748",
   "metadata": {},
   "source": [
    "---\n",
    "myst:\n",
    "  html_meta:\n",
    "    \"description lang=en\": |\n",
    "      User Guide for AgentChat, a high-level API for AutoGen\n",
    "---\n",
    "\n",
    "# Magentic-One\n",
    "\n",
    "[Magentic-One](https://aka.ms/magentic-one-blog) is a generalist multi-agent system for solving open-ended web and file-based tasks across a variety of domains. It represents a significant step forward for multi-agent systems, achieving competitive performance on a number of agentic benchmarks (see the [technical report](https://arxiv.org/abs/2411.04468) for full details).\n",
    "\n",
    "When originally released in [November 2024](https://aka.ms/magentic-one-blog) Magentic-One was [implemented directly on the `autogen-core` library](https://github.com/microsoft/autogen/tree/v0.4.4/python/packages/autogen-magentic-one). We have now ported Magentic-One to use `autogen-agentchat`, providing a more modular and easier to use interface.\n",
    "\n",
    "To this end, the Magentic-One orchestrator `~autogen_agentchat.teams.MagenticOneGroupChat` is now simply an AgentChat team, supporting all standard AgentChat agents and features. Likewise, Magentic-One's `~autogen_ext.agents.web_surfer.MultimodalWebSurfer`, `~autogen_ext.agents.file_surfer.FileSurfer`, and `~autogen_ext.agents.magentic_one.MagenticOneCoderAgent` agents are now broadly available as AgentChat agents, to be used in any AgentChat workflows.\n",
    "\n",
    "Lastly, there is a helper class, `~autogen_ext.teams.magentic_one.MagenticOne`, which bundles all of this together as it was in the paper with minimal configuration.\n",
    "\n",
    "Find additional information about Magentic-one in our [blog post](https://aka.ms/magentic-one-blog) and [technical report](https://arxiv.org/abs/2411.04468).\n",
    "\n",
    "![Autogen Magentic-One example](./images/autogen-magentic-one-example.png)\n",
    "\n",
    "**Example**: The figure above illustrates Magentic-One multi-agent team completing a complex task from the GAIA benchmark. Magentic-One's Orchestrator agent creates a plan, delegates tasks to other agents, and tracks progress towards the goal, dynamically revising the plan as needed. The Orchestrator can delegate tasks to a FileSurfer agent to read and handle files, a WebSurfer agent to operate a web browser, or a Coder or Computer Terminal agent to write or execute code, respectively.\n",
    "\n",
    "```{caution}\n",
    "Using Magentic-One involves interacting with a digital world designed for humans, which carries inherent risks. To minimize these risks, consider the following precautions:\n",
    "\n",
    "1. **Use Containers**: Run all tasks in docker containers to isolate the agents and prevent direct system attacks.\n",
    "2. **Virtual Environment**: Use a virtual environment to run the agents and prevent them from accessing sensitive data.\n",
    "3. **Monitor Logs**: Closely monitor logs during and after execution to detect and mitigate risky behavior.\n",
    "4. **Human Oversight**: Run the examples with a human in the loop to supervise the agents and prevent unintended consequences.\n",
    "5. **Limit Access**: Restrict the agents' access to the internet and other resources to prevent unauthorized actions.\n",
    "6. **Safeguard Data**: Ensure that the agents do not have access to sensitive data or resources that could be compromised. Do not share sensitive information with the agents.\n",
    "Be aware that agents may occasionally attempt risky actions, such as recruiting humans for help or accepting cookie agreements without human involvement. Always ensure agents are monitored and operate within a controlled environment to prevent unintended consequences. Moreover, be cautious that Magentic-One may be susceptible to prompt injection attacks from webpages.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dfaac5",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "Install the required packages:\n",
    "\n",
    "```bash\n",
    "pip install \"autogen-agentchat\" \"autogen-ext[magentic-one,openai]\"\n",
    "\n",
    "# If using the MultimodalWebSurfer, you also need to install playwright dependencies:\n",
    "playwright install --with-deps chromium\n",
    "```\n",
    "\n",
    "If you haven't done so already, go through the AgentChat tutorial to learn about the concepts of AgentChat.\n",
    "\n",
    "Then, you can try swapping out a `autogen_agentchat.teams.SelectorGroupChat` with `~autogen_agentchat.teams.MagenticOneGroupChat`.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import MagenticOneGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    model_client = OpenAIChatCompletionClient(model=\"gpt-4o\")\n",
    "\n",
    "    assistant = AssistantAgent(\n",
    "        \"Assistant\",\n",
    "        model_client=model_client,\n",
    "    )\n",
    "    team = MagenticOneGroupChat([assistant], model_client=model_client)\n",
    "    await Console(team.run_stream(task=\"Provide a different proof for Fermat's Last Theorem\"))\n",
    "    await model_client.close()\n",
    "\n",
    "\n",
    "asyncio.run(main())\n",
    "```\n",
    "\n",
    "To use a different model, see [Models](./tutorial/models.ipynb) for more information.\n",
    "\n",
    "Or, use the Magentic-One agents in a team:\n",
    "\n",
    "```{caution}\n",
    "The example code may download files from the internet, execute code, and interact with web pages. Ensure you are in a safe environment before running the example code.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7248433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from autogen_agentchat.teams import MagenticOneGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.agents.web_surfer import MultimodalWebSurfer\n",
    "# from autogen_ext.agents.file_surfer import FileSurfer\n",
    "# from autogen_ext.agents.magentic_one import MagenticOneCoderAgent\n",
    "# from autogen_agentchat.agents import CodeExecutorAgent\n",
    "# from autogen_ext.code_executors.local import LocalCommandLineCodeExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37be141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)  # Load environment variables from .env file\n",
    "\n",
    "# Load environment variables\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "model_name = os.getenv(\"AZURE_OPENAI_MODEL_NAME\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "base_url = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b56465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "az_model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=deployment_name,\n",
    "    model=model_name,\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=base_url,\n",
    "    # azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    api_key=api_key, # For key-based authentication.\n",
    ")\n",
    "\n",
    "surfer = MultimodalWebSurfer(\n",
    "    \"WebSurfer\",\n",
    "    model_client=az_model_client,\n",
    ")\n",
    "\n",
    "team = MagenticOneGroupChat([surfer], model_client=az_model_client)\n",
    "await Console(team.run_stream(task=\"What is the UV index in Melbourne today?\"))\n",
    "\n",
    "# # Note: you can also use  other agents in the team\n",
    "# team = MagenticOneGroupChat([surfer, file_surfer, coder, terminal], model_client=model_client)\n",
    "# file_surfer = FileSurfer( \"FileSurfer\",model_client=model_client)\n",
    "# coder = MagenticOneCoderAgent(\"Coder\",model_client=model_client)\n",
    "# terminal = CodeExecutorAgent(\"ComputerTerminal\",code_executor=LocalCommandLineCodeExecutor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea369ee",
   "metadata": {},
   "source": [
    "Or, use the `~autogen_ext.teams.magentic_one.MagenticOne` helper class\n",
    "with all the agents bundled together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3333252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from autogen_ext.teams.magentic_one import MagenticOne\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "\n",
    "az_model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=deployment_name,\n",
    "    model=model_name,\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=base_url,\n",
    "    # azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    api_key=api_key, # For key-based authentication.\n",
    ")\n",
    "\n",
    "m1 = MagenticOne(client=az_model_client)\n",
    "task = \"Write a Python script to fetch data from an API.\"\n",
    "result = await Console(m1.run_stream(task=task))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc1fbb8",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "![Autogen Magentic-One architecture](./images/autogen-magentic-one-agents.png)\n",
    "\n",
    "Magentic-One work is based on a multi-agent architecture where a lead Orchestrator agent is responsible for high-level planning, directing other agents and tracking task progress. The Orchestrator begins by creating a plan to tackle the task, gathering needed facts and educated guesses in a Task Ledger that is maintained. At each step of its plan, the Orchestrator creates a Progress Ledger where it self-reflects on task progress and checks whether the task is completed. If the task is not yet completed, it assigns one of Magentic-One other agents a subtask to complete. After the assigned agent completes its subtask, the Orchestrator updates the Progress Ledger and continues in this way until the task is complete. If the Orchestrator finds that progress is not being made for enough steps, it can update the Task Ledger and create a new plan. This is illustrated in the figure above; the Orchestrator work is thus divided into an outer loop where it updates the Task Ledger and an inner loop to update the Progress Ledger.\n",
    "\n",
    "Overall, Magentic-One consists of the following agents:\n",
    "\n",
    "- Orchestrator: the lead agent responsible for task decomposition and planning, directing other agents in executing subtasks, tracking overall progress, and taking corrective actions as needed\n",
    "- WebSurfer: This is an LLM-based agent that is proficient in commanding and managing the state of a Chromium-based web browser. With each incoming request, the WebSurfer performs an action on the browser then reports on the new state of the web page The action space of the WebSurfer includes navigation (e.g. visiting a URL, performing a web search); web page actions (e.g., clicking and typing); and reading actions (e.g., summarizing or answering questions). The WebSurfer relies on the accessibility tree of the browser and on set-of-marks prompting to perform its actions.\n",
    "- FileSurfer: This is an LLM-based agent that commands a markdown-based file preview application to read local files of most types. The FileSurfer can also perform common navigation tasks such as listing the contents of directories and navigating a folder structure.\n",
    "- Coder: This is an LLM-based agent specialized through its system prompt for writing code, analyzing information collected from the other agents, or creating new artifacts.\n",
    "- ComputerTerminal: Finally, ComputerTerminal provides the team with access to a console shell where the Coder’s programs can be executed, and where new programming libraries can be installed.\n",
    "\n",
    "Together, Magentic-One’s agents provide the Orchestrator with the tools and capabilities that it needs to solve a broad variety of open-ended problems, as well as the ability to autonomously adapt to, and act in, dynamic and ever-changing web and file-system environments.\n",
    "\n",
    "While the default multimodal LLM we use for all agents is GPT-4o, Magentic-One is model agnostic and can incorporate heterogonous models to support different capabilities or meet different cost requirements when getting tasks done. For example, it can use different LLMs and SLMs and their specialized versions to power different agents. We recommend a strong reasoning model for the Orchestrator agent such as GPT-4o. In a different configuration of Magentic-One, we also experiment with using OpenAI o1-preview for the outer loop of the Orchestrator and for the Coder, while other agents continue to use GPT-4o."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
